{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benzar80/ProjetWebMeteo/blob/main/TP_Auto_Encodeur_BASHA_DAVENEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TP Apprendre à communiquer avec les auto-encodeurs"
      ],
      "metadata": {
        "id": "oZj3MDztykEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "DCiv4pCmywyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Générer des données\n",
        "1. Générez un vecteur contenant N = 100000 messages aléatoires s ∈ M = {1, 2, · · · , M}."
      ],
      "metadata": {
        "id": "PhuHuJb3xLSc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSyP7YQBsWxV"
      },
      "outputs": [],
      "source": [
        "N = 100000\n",
        "M = 8\n",
        "messages = np.random.randint(1, M+1, N)\n",
        "print(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. Qu’est ce que l’encodage one-hot ?\n",
        "\n",
        " 3. Appliquez un encodage one-hot pour chaque message.\n",
        " La matrice résultante sera donc de taille N × M."
      ],
      "metadata": {
        "id": "2Iq8T6cixfPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages_df = pd.DataFrame({'message': messages})\n",
        "one_hot_encoded = pd.get_dummies(messages_df['message'])\n",
        "print(one_hot_encoded)\n",
        "\n"
      ],
      "metadata": {
        "id": "oicUFBpyydF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Convertir la matrice en tenseur PyTorch."
      ],
      "metadata": {
        "id": "QhNBYPe_BgAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_one_hot = torch.tensor(one_hot_encoded.values)\n",
        "print(tensor_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbsjcTd33jkO",
        "outputId": "91b3ea40-e300-455d-859b-1ba953034e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0,  ..., 0, 1, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 1, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 1, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 1, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Créer un modèle d’auto-encodeur sous PyTorch\n",
        "5. Créez l’encodeur à partir du modèle donné par les auteurs de [6]. On notera que la taille d’entrée est égale à\n",
        "la longueur des vecteurs one-hot, et que la taille de sortie est égale à la longueur d’un nombre complexe. La dernière\n",
        "couche de normalisation permet de prendre en compte les contraintes énergétiques des transmissions. Il ne faut\n",
        "pas confondre le sens de normalisation des auteurs, avec celui des statisticiens où les données sont centrées réduites.\n"
      ],
      "metadata": {
        "id": "_ubGFimHBr4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalisationEnergie(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NormalisationEnergie, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return f.normalize(x)"
      ],
      "metadata": {
        "id": "jMbp--E6v0Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalisationPuissance(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NormalisationPuissance, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x / (m.sqrt(m.mean(x) * m.mean(x)))"
      ],
      "metadata": {
        "id": "OpT458bavav9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianNoiseLayer(nn.Module):\n",
        "    def __init__(self, variance):\n",
        "        super(GaussianNoiseLayer, self).__init__()\n",
        "        self.variance = variance\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise = torch.randn_like(x) * torch.sqrt(torch.tensor(self.variance))\n",
        "        noisy_x = x + noise\n",
        "        return noisy_x"
      ],
      "metadata": {
        "id": "AHlcSRbeyAYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizen, sigma_squared):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(M,M),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(M,2),\n",
        "            NormalisationEnergie(input_size, hidden_sizen)\n",
        "            #NormalisationPuissance()\n",
        "        )\n",
        "        self.noise = GaussianNoiseLayer(\n",
        "            sigma_squared\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2,M),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(M,M),\n",
        "            nn.Softmax(dim=M),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_encoded = self.encoder(x)\n",
        "        x_noisy = self.noise(x_encoded)\n",
        "        x_decoded = self.decoder(x_noisy)\n",
        "        return x_decoded\n"
      ],
      "metadata": {
        "id": "Mv28X_bQF5wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Expliquez ce qu’est une fonction d’activation."
      ],
      "metadata": {
        "id": "Ht8_jTLB7TUj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RiFVpJhU8SBA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}